{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Model       Gov(R(1/2/L))   SumScr(R(1/2/L))    QMSum(R(1/2/L))  \\\n",
      "0   InstructLM    12.0 / 3.5 / 7.6    6.8 / 0.5 / 5.2   11.3 / 2.0 / 8.4   \n",
      "1      AceInst  45.9 / 14.4 / 20.8   17.8 / 2.9 / 9.9   16.1 / 3.5 / 9.6   \n",
      "2       LaMini  29.3 / 11.1 / 16.8  20.4 / 2.3 / 12.6  21.8 / 6.7 / 16.1   \n",
      "3  llama-i(3B)  50.3 / 19.7 / 24.1  28.1 / 6.5 / 15.2  29.2 / 7.1 / 18.1   \n",
      "4         Qwen  44.3 / 17.2 / 21.5  18.6 / 2.8 / 10.5  30.6 / 7.0 / 18.7   \n",
      "\n",
      "  Qasper(F1) NarQA(F1) Qual(EM)        Avg  \n",
      "0        5.4       4.8      0.0   6.716667  \n",
      "1        5.0       2.8      0.0  14.600000  \n",
      "2        3.3       5.2      0.0  13.333333  \n",
      "3       13.3      13.3      0.0  22.366667  \n",
      "4        7.8      12.0      4.8  19.683333  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory where results are stored\n",
    "base_dir = \"Evaluation_results\"\n",
    "\n",
    "short_model_names = {\"MBZUAI_LaMini_GPT_1.5B\": \"LaMini\",\"Qwen_Qwen2.5_1.5B_Instruct\":\"Qwen\",\"instruction_pretrain_InstructLM_1.3B\":\"InstructLM\",\"nvidia_AceInstruct_1.5B\":\"AceInst\",\"_assets_models_meta_llama_3.2_instruct_3b\":\"llama-i(3B)\"}\n",
    "\n",
    "#print(short_model_names.keys())\n",
    "# List to store extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate over all model directories\n",
    "for model_name in os.listdir(base_dir):\n",
    "    model_path = os.path.join(base_dir, model_name)\n",
    "    result_file = os.path.join(model_path, \"results.json\")\n",
    "    #print(model_name)\n",
    "    \n",
    "    if os.path.isdir(model_path) and os.path.exists(result_file):\n",
    "        with open(result_file, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "            \n",
    "            # Extract metrics and ensure all datasets have same format\n",
    "            row = {\"Model\": short_model_names.get(model_name, model_name)}\n",
    "            \n",
    "            for dataset in [\"gov_report\", \"summ_screen_fd\", \"qmsum\", \"qasper\", \"narrative_qa\", \"quality\"]:\n",
    "                metrics = results.get(dataset, {})\n",
    "                \n",
    "                if \"Rouge1\" in metrics:\n",
    "                    row[f\"{dataset}\"] = f\"{metrics.get('Rouge1', 0) * 100:.1f} / {metrics.get('Rouge2', 0) * 100:.1f} / {metrics.get('RougeL', 0) * 100:.1f}\"\n",
    "                elif \"f1_score\" in metrics:\n",
    "                    row[f\"{dataset}\"] = f\"{metrics.get('f1_score', 0) * 100:.1f}\"\n",
    "                elif \"EM_score\" in metrics:\n",
    "                    row[f\"{dataset}\"] = f\"{metrics.get('EM_score', 0) * 100:.1f}\"\n",
    "                else:\n",
    "                    row[f\"{dataset}\"] = \"N/A\"\n",
    "            \n",
    "            data.append(row)\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Rename columns for better readability\n",
    "df.rename(columns={\n",
    "    \"gov_report\": \"Gov(R(1/2/L))\",\n",
    "    \"summ_screen_fd\": \"SumScr(R(1/2/L))\",\n",
    "    \"qmsum\": \"QMSum(R(1/2/L))\",\n",
    "    \"qasper\": \"Qasper(F1)\",\n",
    "    \"narrative_qa\": \"NarQA(F1)\",\n",
    "    \"quality\": \"Qual(EM)\"\n",
    "}, inplace=True)\n",
    "\n",
    "df[\"Avg\"] = df.iloc[:, 1:].apply(lambda row: sum([float(x.split('/')[0]) if '/' in x else float(x) for x in row if x != \"N/A\"]) / len(row), axis=1)\n",
    "\n",
    "# Print the table\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scrolls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
