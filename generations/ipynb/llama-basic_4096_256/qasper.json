{
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "Unif and Stopword.",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "No.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "The 8,640 sentences were generated by replacing variables in 11 templates with different combinations of noun phrase pairs and emotion words, with the goal of creating sentences that differ only in one word corresponding to gender or race.",
    "518dae6f936882152c162058895db4eca815e649": "The article does not explicitly state the number of layers in the UTCNN model. However, it describes the architecture of the model, which includes multiple convolutional layers, pooling layers, and fully connected layers. Based on the description, it can be inferred that the UTCNN model has at least 5 layers: \n\n1. Convolutional layer\n2. Pooling layer\n3. Convolutional layer\n4. Pooling layer\n5. Fully connected layer\n\nHowever, the article does not provide information on the number of layers in the model.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "No, the paper does not provide any case studies to illustrate how one can use Macaw for CIS research.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "The three levels of the annotation scheme are:\n\n1. Level A: Offensive language detection (OFF vs NOT)\n2. Level B: Categorization of Offensive Language (TIN and UNT)\n3. Level C: Offensive Language Target Identification (IND, GRP, and OTH)",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "The results show that error detection performance is substantially improved by making use of artificially generated data, created by any of the described methods.",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "The baseline model used in the article is not explicitly mentioned, but it is implied to be a system that was submitted to the BioASQ 7 competition, which is a biomedical document classification, document retrieval, and question answering competition. The article mentions that the authors did not participate in the \"ideal answer\" test, but they provide an overview of their submissions to the semantic question answering task (7b, Phase B) of BioASQ 7.",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "The dataset comprises a total of 353 conversations from 40 speakers, with a total duration of 41 hours.",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "The baseline classification uses a combination of n-grams, bag-of-words, common words, and hashtags.",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "The supervised scores of the words are calculated as follows: for a target word in the corpus, the minimum, maximum, and average polarity scores of words occurring in the same contexts as the target word are taken into consideration, in addition to the target word's polarity score.",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "The article introduces the following data simulation techniques:\n\n1. Copy: a simple technique where the source side is a mere copy of the target-side data.\n2. Copy-marked: a technique where the source vocabulary is augmented with a copy of the target vocabulary, with target words marked to avoid confusion with homographic words.\n3. Copy-dummies: a technique where each word is replaced with \"dummy\" tokens to observe the training of noisy and uninformative source sentences.\n4. Generative Adversarial Networks (GANs): a technique where a generator encodes pseudo-source sentences to fool a discriminator trained to distinguish natural from artificial sources.\n5. Forward translation (FT): a technique where the target side of the corpus is artificial and generated using the baseline NMT applied to a natural source.",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "Information extraction-oriented metrics.",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "The article mentions the following linguistics features:\n\n1. Segmentation (SEG): the position of the character in a word segment.\n2. Prior: diacritics seen in the training set per segment.\n3. CASE: whether the letter expects a core word diacritic or a case ending.\n4. POS (Part-of-speech) tags: gender and number of stems, prefixes, and suffixes.\n5. Morphological features: stem templates to capture morphological patterns.\n6. Surface-level features: affixes, leading and trailing characters in words and stems, and the presence of words in large gazetteers of named entities.\n7. Syntactic features: parsing, dependency parsing, and identification of indeclinability.",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "The training data was translated into Spanish using the machine translation platform Apertium.",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "The proposed model is compared to a base model (LSTM with self-attention) and two other models: ELMo Only (using only the pre-trained ELMo model) and ELMo+Topic (combining the pre-trained ELMo model with the proposed topic-attention model).",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "The article does not explicitly mention the specific traditional linguistic features used. However, it mentions that the feature set used includes lexical, implicit incongruity, and explicit incongruity features, which are borrowed from various literature, predominantly from the work of Joshi (2015).",
    "b970f48d30775d3468952795bc72976baab3438e": "They tackle issues such as the interpretation of results, the validation of models, and the limitations of computational text analysis, including the potential for spurious features, the need for human judgment and expertise, and the importance of considering the social and cultural context of the data.",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "No"
}