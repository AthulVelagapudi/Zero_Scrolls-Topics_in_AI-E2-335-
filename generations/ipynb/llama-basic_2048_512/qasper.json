{
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "The baselines used are Unif and Stopword.",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "No, the article does not mention the analysis of transformer-based architectures.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "The article does not explicitly state the criteria used to select the 8,640 English sentences for the Equity Evaluation Corpus (EEC).",
    "518dae6f936882152c162058895db4eca815e649": "The article does not explicitly mention the number of layers in the UTCNN model.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "The paper mentions that Macaw supports Wizard of Oz studies or intermediary-based information seeking studies, and provides an architecture for such setup, but it does not provide specific case studies to illustrate how one can use Macaw for CIS research.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "Level A: Offensive language Detection, \nLevel B: Categorization of Offensive Language, \nLevel C: Offensive Language Target Identification",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "The results show that error detection performance is substantially improved by making use of artificially generated data, created by any of the described methods.",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "The baseline model used in the article is not explicitly mentioned, but it can be inferred that the baseline model is the BioBERT BIBREF0 model, which was fine-tuned for the biomedical question answering task.",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "The article does not explicitly state the size of the created dataset, but it mentions that the simulated dataset has 1,264 samples in the Base Set, 1,280 samples in the Augmented Set, and 944 samples in the Real-World Set.",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "The baseline classification uses a bag-of-words feature.",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "The supervised scores of the words are calculated by combining unsupervised and supervised scores using official dictionaries for Turkish, and then a unified score is generated for each dimension of the word embeddings.",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "The article introduces the following data simulation techniques:\n\n1. Back-translation (BT): generating artificial parallel data via backward translation of monolingual target texts.\n2. Stupid BT: using a copy of the target sentence instead of a natural source sentence.\n3. GANs (Generative Adversarial Networks): using GANs to make pseudo-source sentences closer to natural source sentences.\n4. Target Language Models (LM): using a target side Language Model to improve the decoder.",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "Content Selection (CS)",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "The article mentions the following linguistics features:\n\n1. Surface features:\n\t* Word surface forms\n\t* Stems\n\t* Prefixes\n\t* Suffixes (including noun suffixes)\n2. Morphological features:\n\t* Stem templates\n3. Syntactic features:\n\t* Part-of-speech (POS) tagging\n\t* Dependency parsing\n4. Other features:\n\t* Sukun words (a type of diacritic)\n\t* Named entities\n\t* Head and tail characters\n\t* Bigram language model\n\t* Pre-trained embeddings\n\t* Attention mechanisms",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "The training data was translated using the machine translation platform Apertium.",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "The proposed model is compared to a base model (LSTM with self-attention) and two other models: ELMo Only (using only the pre-trained ELMo model) and ELMo+Topic (using both the pre-trained ELMo model and the pre-trained Doc2vec model).",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "The article does not explicitly mention the specific traditional linguistic features used. However, it mentions that the feature set from joshi2015harnessing subsumes unigram features and features from other reported systems, suggesting that unigram features are part of the traditional linguistic features used.",
    "b970f48d30775d3468952795bc72976baab3438e": "They tackle issues that are not on the forefront of computational text analysis, such as the subtleties of meaning and interpretation, the importance of human time and attention, the challenges of incorporating cultural and social context, and the need for validation and reliability in the analysis.",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "No"
}