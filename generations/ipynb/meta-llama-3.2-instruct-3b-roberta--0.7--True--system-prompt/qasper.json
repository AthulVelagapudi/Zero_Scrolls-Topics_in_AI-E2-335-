{
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "The baselines used are Unif Stopword and Unif encoder, which are compared to the proposed constrained objective model.",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "No, the article does not mention transformer-based architectures.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "The 8,640 English sentences were selected using eleven sentence templates, each with two variables: person (male or female) and emotion (anger, fear, joy, or sadness). The templates were designed to include a mix of emotional and non-emotional sentences, with five words for each emotion and varying intensities, taken from Roget's Thesaurus. The sentences were generated by instantiating the variables with pre-chosen values, and a total of 8,640 sentences were manually examined to ensure grammatical correctness.",
    "518dae6f936882152c162058895db4eca815e649": "The article does not explicitly state the number of layers in the UTCNN model.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "The paper mentions a Wizard of Oz study, which is an intermediary-based information seeking study, as an example of how Macaw can be used for CIS research.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "Level A, Level B, Level C.",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "Improved error detection performance on the FCE dataset.",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "The baseline model used in the experiments was the SQuAD 2.0 model.",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "The created dataset is 1,264 samples in the Base Set, 1,280 samples in the Augmented Set, and 944 samples in the Real-World Set.",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "Support Vector Machine (SVM) with radial basis function kernel.",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "Supervised scores of words are computed using a formula that takes into account the polarity scores of words in the same context as the target word, as well as the self-score of the target word and the minimum, maximum, and average polarity scores of words in the review.",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "The article introduces the following data simulation techniques:\n\n1. Back-Translation (BT): generating artificial parallel data by reversing the translation process.\n2. Forward-Translation (FT): generating artificial parallel data by translating monolingual source texts to the target language.\n3. GANs (Generative Adversarial Networks): using a generator to create pseudo-source sentences and a discriminator to evaluate the quality of the generated sentences.\n4. Copy-Marked Back-Translation: modifying the BT technique by copying the target side of the sentence instead of the source side.\n5. Copy-Marked Forward-Translation: modifying the FT technique by copying the source side of the sentence instead of the target side.\n\nThese techniques aim to generate high-quality artificial parallel data for NMT systems, which can improve their performance on out-of-domain tasks.",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "BLEU score and qualitative metrics.",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "The article mentions the following linguistics features:\n\n1. POS (Part-of-speech) tags\n2. Stem-templates\n3. Morphological features\n4. Syntactic features\n5. Case endings\n6. Word segmentation\n7. Bigram language model\n8. Sukun (a type of diacritic mark)\n9. Kasra (a type of diacritic mark)\n10. Damma (a type of diacritic mark)\n11. Gemination\n12. Nunation\n13. Shadda (a type of diacritic mark)\n14. Gemination\n15. Virtual CE (a type of diacritic mark)\n16. Prefixes\n17. Suffixes\n18. Gender\n19. Number\n20. Word-level features\n21. Character-level features\n22. Contextual features\n23. Dependency parsing\n24. Semantic roles\n25. Idafa (a type of diacritic mark)\n26. Named entities\n27. Word boundaries\n28. Word segmentation\n29. Morphological analysis\n30. Syntactic analysis\n31. Lexical selection\n32. Diacritics recovery\n33. Character-level convolutional neural networks\n34. Attention mechanisms\n35. Joint modeling of core case diacritics.",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "The training data was translated using the Apertium machine translation platform, with the exception of the SentiStrength English version, which was replaced by the Spanish variant.",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "The proposed model is compared to traditional models, including Na\u00efve Bayesian classifier, and deep learning models such as LSTM and CNN, as well as a combination of these models.",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "unanswerable",
    "b970f48d30775d3468952795bc72976baab3438e": "They tackle issues such as the limitations of computational text analysis, the need for interpretability, the challenge of handling linguistic variation, the importance of contextualization, the need for careful consideration of data quality and provenance, the potential for biases in data and models, and the need for human judgment and expertise in the analysis process.",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "No"
}