{
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "Unif and Stopword.",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "No, the article does not analyze transformer-based architectures.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "The 8,640 English sentences were generated using eleven sentence templates, with two variables: a person noun phrase and an emotion word, and were instantiated with pre-chosen values for each variable to create a total of 8,640 sentences.",
    "518dae6f936882152c162058895db4eca815e649": "The article does not explicitly state the number of layers in the UTCNN model.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "The paper mentions that Macaw supports Wizard of Oz studies or intermediary-based information seeking studies, but it does not provide specific case studies to illustrate how one can use Macaw for CIS research.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "The three levels of the annotation scheme are:\n\n1. Level A: Offensive language detection (OFF vs NOT)\n2. Level B: Categorization of offensive language (type, targeted vs untargeted)\n3. Level C: Offensive language target identification (individual, group, or others)",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "Our results show that error detection performance is substantially improved by making use of artificially generated data, created by any of the described methods.",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "The baseline model was BioBERT.",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "The created dataset consists of 353 conversations from 40 speakers, amounting to 41 hours of data.",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "The baseline classification system uses support vector machine with radial basis function kernel and extra tree classifier.",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "The supervised scores of the words are calculated using the formula: $w_{t} = \\frac{N_{t} + \\lambda}{N + \\lambda} = \\frac{N_{t}}{N + \\lambda}$, where $N_{t}$ is the number of documents (reviews or tweets) in which word $t$ occurs in the dataset of positive polarity, $N$ is the number of all the words in the corpus of positive polarity, and $\\lambda$ is a smoothing parameter.",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "The article introduces the following data simulation techniques:\n\n1. Back-translation (BT)\n2. Copying the target sentence\n3. Copy-marking (augmenting the source vocabulary with a copy of the target vocabulary)\n4. Copy-dummies (replacing words with \"dummy\" tokens)\n5. Noise injection (adding random words and permuting the remaining words in the target sentence)\n6. Generative Adversarial Networks (GANs) to make pseudo-source sentences closer to natural source sentences",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "Information extraction-oriented metrics.",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "The article mentions the following linguistics features used for diacritics recovery:\n\n1. Part-of-Speech (POS) tags\n2. Gender and number features\n3. Morphological patterns\n4. Affixes\n5. Stem templates\n6. POS tagging\n7. Bigram language model\n8. Unigram language model\n9. Syntactic features\n10. Surface level features\n11. Stem features\n12. Word surface forms\n13. Leading and trailing character unigrams and bigrams\n14. Named entity recognition\n15. Indeclinability detection\n16. Dependency parsing",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "The training data was translated using the machine translation platform Apertium.",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "The proposed model is compared to traditional models (including Na\u00efve Bayesian classifier, Support Vector Machine, logistic regression classifier, Naive Bayes classifier, and random forest) and deep models (including LSTM with self-attention, LSTM with pre-trained word embeddings, and CNN).",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "unanswerable",
    "b970f48d30775d3468952795bc72976baab3438e": "They tackle issues such as the complexity of human interpretation, the importance of contextualization, the need for careful consideration of data provenance, the potential for biases in data collection and annotation, and the challenge of ensuring that computational models are interpretable and transparent.",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "No."
}