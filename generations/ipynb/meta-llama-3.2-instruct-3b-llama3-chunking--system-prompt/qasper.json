{
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "The baselines used are Unif and Stopword.",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "No, the article does not mention the analysis of transformer-based architectures for sentence pair modeling.",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "The 8,640 English sentences were generated using eleven sentence templates, each with two variables: a person noun phrase (male or female) and an emotion word (or no emotion word). The sentences were created by instantiating these variables with pre-chosen values, resulting in a total of 8,640 sentences.",
    "518dae6f936882152c162058895db4eca815e649": "The article does not explicitly mention the number of layers in the UTCNN model.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "Yes, the paper mentions that Macaw supports Wizard of Oz studies or intermediary-based information seeking studies, where the seeker performs different information seeking actions with Macaw, and all seeker-intermediary and intermediary-system interactions will be logged for further analysis.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "The three levels of the annotation scheme are: \n\n1. Level A: Offensive language detection, distinguishing between offensive (OFF) and non-offensive (NOT) tweets.\n2. Level B: Categorization of offensive language, distinguishing between targeted (TIN) and untargeted (UNT) insults and threats, and between targeted insults/threats and general profanity.\n3. Level C: Offensive language target identification, distinguishing between individual (IND), group (GRP), and other (OTH) targets of insults and threats.",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "They show that error detection performance is substantially improved by making use of artificially generated data, and that their approach consistently outperforms the system by Felice2014a, achieving the best performance on all datasets.",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": "The baseline model was BioBERT fine-tuned on SQuAD 2.0.",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "The dataset comprises a total of 353 conversations from 40 speakers, with approximately 41 hours of data.",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "Support vector machine.",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "The supervised scores of the words are calculated as the number of documents (reviews or tweets) in which the word occurs in the dataset of positive polarity, divided by the total number of all words in the corpus of positive polarity.",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "The article introduces the following data simulation techniques: \n\n1. Back-Translation (BT): generating artificial parallel data by translating monolingual target texts back to the source language.\n2. Copy: copying the target side of the corpus to generate pseudo-source texts.\n3. Copy-marked: augmenting the source vocabulary with a copy of the target vocabulary, marked with a special language identifier.\n4. Copy-dummies: replacing words with \"dummy\" tokens in the source texts.\n5. Noise: adding noise to the target sentences copied from the source.\n6. Generative Adversarial Networks (GANs): using a generator to encode pseudo-sentence pairs and a discriminator to distinguish between natural and artificial sources.",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "Content Ordering (CO)",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "The article mentions the following linguistics features used in the proposed DNN model for diacritization:\n\n1. Surface level features:\n\t* Characters\n\t* Segmentation information\n\t* Leading and trailing characters\n\t* Named entities\n\t* Word surface forms\n\t* Stem templates\n\t* POS tagging information\n\t* Morphological patterns\n2. Morphological features:\n\t* Stem templates\n\t* Prefixes\n\t* Suffixes\n3. Syntactic features:\n\t* POS tags\n\t* Gender and number features\n\t* Part-of-speech (POS) tags\n\t* Morphological patterns\n\t* Affixes",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "The training data was translated into Spanish using the machine translation platform Apertium.",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "The proposed model is compared to traditional models (TF-IDF, Naive Bayes, logistic regression, and random forest) and neural models (LSTM with self-attention, ELMo, and Doc2vec).",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "Unanswerable",
    "b970f48d30775d3468952795bc72976baab3438e": "They tackle issues such as the complexity of cultural and social concepts, the challenge of incorporating subtleties of meaning and interpretation, the difficulty of defining and measuring hate speech, and the problem of operationalizing and analyzing concepts that are highly contested.",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "No"
}