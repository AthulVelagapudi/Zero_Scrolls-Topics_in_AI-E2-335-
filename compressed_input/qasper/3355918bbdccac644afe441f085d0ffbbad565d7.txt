<|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are a helpful assistant. Always follow the task instruction carefully. The first paragraph before the first double line break contains the task instruction. Generate text as a natural continuation of the user message. Do not include any meta-commentary or explanations.<|eot_id|>
<|start_header_id|>user<|end_header_id|>

You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write "unanswerable". If the question is a yes/no question, answer "yes", "no", or "unanswerable".

Article:
Introduction Sent analysis has recently been the in). is to and categorise expressed by reviewers on a topic or.   analysis beaged in, media, and.  Although many studies have been conducted for sentiment analysis in widely spoken languages, this topic is still immature for Turkish and many other languages.Ne networksform the conventional in most, including analysis BIBREF.  In these, embedding are fed to the problem and the words more “meaningful” and robust.  Those embeddings indicate how close the words are to each other in the vector space model (VSM). the studies utilise embedings,vec BIBREF1, which take into account the syntactic and semantic representations of the words only.  Discarding the sentimental aspects of words may lead to words of different polarities being close to each other in the VSM, if they share similar semantic and syntactic features.For Turkish, there are only a few studies which leverage sentimental information in generating the word and document embeddings.  Unlike the studies conducted for English and other widely-spoken languages, in this paper, we use the official dictionaries for this language and combine the unsupervised and supervised scores to generate a unified score for each dimension of the word embeddings in this task.  Our main contribution is to create original and effective word vectors that capture syntactic, semantic, and sentimental characteristics of words, and use all of this knowledge in generating embeddings.We also the wordvecings on corpus.  Besides using these word embeddings, we also generate hand-crafted features on a review basis and create document vectors.  We evaluate those embeddings on two datasets.  The results show that we outperform the approaches which do not take into account the sentimental information.We also had better performances than other studies carried out on sentiment analysis in Turkish media.  We also evaluated our novel embedding approaches on two English corpora of different genres.  We outperformed the baseline approaches for this language as well.  The source code and datasets are publicly available.The paper is organised as follows.  In Section 2, we present the existing works on sentiment classification.  In Section 3, we describe the methods proposed in this work.The experimental results are shown and the main contributions of our proposed approach are discussed in Section 4.  In Section 5, we conclude the paper.  Related WorkIn the literature, the main consensus is that the use of dense word embeddings outperform the sparse embeddings in many tasks.  Latent semantic analysis (LSA) used to be the most popular method in generating word embeddings before the invention of the word2vec and other word vector algorithms which are mostly created by shallow neural network models.  Although many studies have been employed on generating word vectors including both semantic and sentimental components, generating and analysing the effects of different types of embeddings on different tasks is an emerging field for Turkish.entlet is in BIBREF2 to extract mixture of latent topics.  However, it focusses on finding the latent topics of a document, not the word meanings themselves.  In BIBREF3, LSA is utilised to generate word vectors, leveraging indirect co-occurrence statistics.These the of sparse vectors BIBREF.   the prior also the sentimental of a word when creating word vectors BIBREF5, BIBREF6, BIBREF7.  A model with semantic and sentiment components is built in BIBREF8, making use of star-ratings of reviews.In BIBREF9, a sentiment lexicon is induced preferring the use of domain-specific co-occurrence statistics over the word2vec method and they outperform the latter.  In a recent work on sentiment analysis in Turkish BIBREF10, they learn embeddings using Turkish social media.  They use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach.Weform this baseline approach using more effective and supervised.In, the on learning sentimentspecificings relies onIn BIBREF, as and a-M ( short-term memory) neural network model is built to learn sentiment-aware word embeddings.In BIBREF a network learnsings is using contextual information the and supervised.This work the supervised information by utilising emoticons as features.  Most of our approaches do not rely on a neural network model in learning embeddings. However, they produce state-of-the-art results.Methodology  We generate several word vectors, which capture the sentimental, lexical, and contextual characteristics of words.  In addition to these mostly original vectors, we also create word2vec embeddings to represent the corpus words by training the embedding model on these datasets.After generating these, we combine them with hand-crafted features to create document vectors and perform classification, as will be explained in Section 3.5.  Methodology :::  Corpus-based ApproachContextual information is informative in the sense that, in general, similar words tend to appear in the same contexts.  For example, the word smart is more likely to cooccur with the word hardworking than with the word lazy.  This similarity can be defined semantically and sentimentally. the corpusbased, we capture both these characteristics and generateings to a.  Firstly, we construct a matrix whose entries correspond to the number of cooccurrences of the row and column words in sliding windows.  Diagonal entries are assigned the number of sliding windows that the corresponding row word appears in the whole corpus.We then normalise each dividing the maximum score in it.  Secondly, we perform the principal component analysis (PCA) method to reduce the dimensionality. It captures latent meanings and takes into account high-order cooccurrence removing noise.  The attribute (column) number of the matrix is reduced to 200.We then compute each row pair $$ as in (DISPLAY_FORM) to find similar two vectors (. , the are to a dissimilarity matrix.  Then, we feed the matrix as input into the fuzzy c-means clustering algorithm.We chose the number of clusters as 200, as it is considered a standard for word embeddings in the literature.  After clustering, the dimension i for a corresponding word indicates the degree to which this word belongs to cluster i.  The intuition behind this idea is that if two words are similar in the VSM, they are more likely to belong to the same clusters with akin probabilities.  In the end, each word in the corpus is represented by a 200-dimensional vector.In to this also perform the courrencerices, we the matrix $^{P = U$.  itive) scores calculated and the truncated singular value decomposition is computed.  We take into account the U matrix only for each word.We have chosen the singular value number as 200.  That is, each word in the corpus is represented by a 200-dimensional vector as follows.  Methodology :::Dictionary-based Approach  In Turkish, there do not exist well-established sentiment lexicons as in English.  In this approach, we made use of the TDK (Türk Dil Kurumu - “Turkish Language Institution”) dictionary to obtain word polarities.Although it is not a sentiment lexicon, combining it with domain-specific polarity scores obtained from the corpus led us to have state-of-the-art results.  We first construct a matrix whose row entries are corpus words and column entries are the words in their dictionary definitions.  We followed the boolean approach.For, for the word the column words in its dictionary definition are given a.  Those words not appearing in the definition of cat are assigned a score of 0 for that corresponding row entry.  When we performed clustering on this matrix, we observed that those words having similar meanings are, in general, assigned to the same clusters.However, this similarity fails in capturing the sentimental characteristics.  For instance, the words happy and unhappy are assigned to the same cluster, since they have the same words, such as feeling, in their dictionary definitions.  However, they are of opposite polarities and should be discerned from each other., we a metric to move such words the, have common their.  We multiply each in corresponding row word's raw supervised score, thereby having more meaningful clusters.  Using the training data only, the supervised polarity score per word is calculated as in (DISPLAY_FORM4).Here, $ w_{t}$ denotes the sentiment score of word $t$, $N_{t}$ is the number of documents (reviews or tweets) in which $t$ occurs in the dataset of positive polarity, $N$ is the number of all the words in the corpus of positive polarity.  $N^{\prime }$ denotes the corpus of negative polarity.  $N^{\prime }_{t}$ and $N^{\prime }$ denote similar values for the negative polarity corpus.  We perform normalisation to prevent the imbalance problem and add a small number to both numerator and denominator for smoothing.As an alternative to multiplying with the supervised polarity scores, we also separately multiplied all the row scores with only +1 if the row word is a positive word, and with -1 if it is a negative word.  We have observed it boosts the performance more compared to using raw scores.The effect of this multiplication is exemplified in Figure FIGREF7, showing the positions of word vectors in the VSM.  Those “x" words are sentimentally negative words, those “o" words are sentimentally positive ones.  On the top coordinate plane, the words of opposite polarities are found to be close to each other, since they have common words in their dictionary definitions.  Only the information concerned with the dictionary definitions are used there, discarding the polarity scores.However, when we utilise the supervised score (+1 or -1), words of opposite polarities (e.g. “happy" and “unhappy") get far away from each other as they are translated across coordinate regions.  Positive words now appear in quadrant 1, whereas negative words appear in quadrant 3.  Thus, in the VSM, words that are sentimentally similar to each other could be clustered more accurately.  Besides clustering, we also employed the SVD method to perform dimensionality reduction on the unsupervised dictionary algorithm and used the newly generated matrix by combining it with other subapproaches.The of is as 200 again the $$.The in   using and this subach the English we theicon BIBREF  We have achieved better results for the dictionary-based algorithm when we employed the SVD reduction method compared to the use of clustering.Methodology :::  Supervised Contextual 4-scoresOur last is a simple that uses four supervised scores each word the.  We extract scores follows  For a word we scan all of its contexts  In word'sarity score (the), the scores of words the same the target word, minimum, maximum, and average scores are taken into consideration.The word polarity scores are computed using (DISPLAY_FORM4).  Here, we obtain those scores from the training data.  The intuition behind this method is that those four scores are more indicative of a word's polarity rather than only one (the self score).This approach is fully supervised unlike the previous two approaches.  Methodology :::  Combination of the Word EmbeddingsIn addition to using the three approaches independently, we also combined all the matrices generated in the previous approaches.  That is, we concatenate the reduced forms (SVD - U) of corpus-based, dictionary-based, and the whole of 4-score vectors of each word, horizontally.  Accordingly, each corpus word is represented by a 404-dimensional vector, since corpus-based and dictionary-based vector components are each composed of 200 dimensions, whereas the 4-score vector component is formed by four values.The main the ensemble that some approaches for others.  For example, the corpus-based approach captures the domain-specific, semantic, and syntactic characteristics.  On the other hand, the 4-scores method captures supervised features, and the dictionary-based approach is helpful in capturing the general semantic characteristics.That is, combining those three approaches makes word vectors more representative.  Methodology :::  Generating Document VectorsAfter creating severalings as we create document (review).  For each document, we sum all the vectors of words occurring in that document and take their average.  In addition to it, we extract three hand-crafted polarity scores, which are minimum, mean, and maximum polarity scores, from each review.These polarity scores of words are computed as in (DISPLAY_FORM4).  For example, if a review consists of five words, it would have five polarity scores and we utilise only three of these sentiment scores as mentioned.  Lastly, we concatenate these three scores to the averaged word vector per review.That, each is the average word its constituent wordings and three supervised.   then these theVMThe our is Figure FIGREF.  When thevised, are vectors created on word supervised scores a basis, we have better state-of-the-art results.Datasets  We utilised two datasets for both Turkish and English to evaluate our methods.For Turkish, as the first dataset, we utilised the movie reviews which are collected from a popular website.  The number of reviews in this movie corpus is 20,244 and the average number of words in reviews is 39.  Each of these reviews has a star-rating score which is indicative of sentiment.These polarity are between the values 0. and, at.  We consider a be negative it the is or   if is 4, it is assumed to be positive.  We have randomly selected 7,020 negative and 7,020 positive reviews and processed only them.The second Turkish dataset is the Twitter corpus which is formed of tweets about Turkish mobile network operators.  Those tweets are mostly much noisier and shorter compared to the reviews in the movie corpus.  In total, there are 1,716 tweets. 973 of them are negative and 743 of them are positive.These tweets are manually annotated by two humans, where the labels are either positive or negative.  We measured the Cohen's Kappa inter-annotator agreement score to be 0.82.  If there was a disagreement on the polarity of a tweet, we removed it.We alsoised two other datasets in English to theling our.   a movie corpus the web   are,331 positive reviews and 5,331 negative reviews in this corpus.  The other is a Twitter dataset, which has nearly 1.6 million tweets annotated through a distant supervised method BIBREF14.These tweets have positive, neutral, and negative labels.  We have selected 7,020 positive tweets and 7,020 negative tweets randomly to generate a balanced dataset.  Experiments :::Preprocessing  In Turkish, people sometimes prefer to spell English characters for the corresponding Turkish characters (e.g. i for ı, c for ç) when writing in electronic format.  To normalise such words, we used the Zemberek tool BIBREF15.All punctuation marks except “!" and “?" are removed, since they do not contribute much to the polarity of a document.  We took into account emoticons, such as “:))", and idioms, such as “kafayı yemek” (lose one's mind), since two or more words can express a sentiment together, irrespective of the individual words thereof.  Since Turkish is an agglutinative language, we used the morphological parser and disambiguator tools BIBREF16, BIBREF17.  We also performed negation handling and stop-word elimination.Ination we append an if it is negated.  For example, “güzel değil" (not beautiful) is redefined as “güzel_" (beautiful_) in the feature selection stage when supervised scores are being computed.  Experiments :::Hyperparameters  We used the LibSVM utility of the WEKA tool.  We chose the linear kernel option to classify the reviews.We trainedvec the foura the library BIBREF18 the.The dimension of are  As,ings, are generated theering and theVD also of  For- we the at, it converges.Experiments :::  ResultsWe evaluated our models on four corpora, which are the movie and the Twitter datasets in Turkish and English.  All of the embeddings are learnt on four corpora separately.  We have used the accuracy metric since all the datasets are completely or nearly completely balanced.  We performed 10-fold cross-validation for both of the datasets.We used the approximate randomisation technique to test whether our results are statistically significant.  Here, we tried to predict the labels of reviews and assess the performance.  We obtained varying accuracies as shown in Table TABREF17.“3 feats" features are those hand-crafted features we extracted, which are the minimum, mean, and maximum polarity scores of the reviews as explained in Section 3.5.  As can be seen, at least one of our methods outperforms the baseline word2vec approach for all the Turkish and English corpora, and all categories.  All of our approaches performed better when we used the supervised scores, which are extracted on a review basis, and concatenated them to word vectors.  Mostly, the supervised 4-scores feature leads to the highest accuracies, since it employs the annotational information concerned with polarities on a word basis.As can be seen in Table TABREF17, the clustering method, in general, yields the lowest scores.  We found out that the corpus - SVD metric does always perform better than the clustering method.  We attribute it to that in SVD the most important singular values are taken into account.The corpus - SVD technique outperforms the word2vec algorithm for some corpora.  When we do not take into account the 3-feats technique, the corpus-based SVD method yields the highest accuracies for the English Twitter dataset.  We show that simple models can outperform more complex models, such as the concatenation of the three subapproaches or the word2vec algorithm.  Another interesting finding is that for some cases the accuracy decreases when we utilise the polarity labels, as in the case for the English Twitter dataset. the TDK dictionary covers the domain vocabulary the movie the dictionary method.   dictionary lacks many words, the tweets; therefore, its performance is not the best of all.  When the TDK method is combined with the 3-feats technique, we observed a great improvement, as can be expected.Success rates obtained for the movie corpus are much better than those for the Twitter dataset for most of our approaches, since tweets are, in general, much shorter and noisier.  We also found out that, when choosing the p value as 0.05, our results are statistically significant compared to the baseline approach in Turkish BIBREF10.  Some of our subapproaches also produce better success rates than those sentiment analysis models employed in English BIBREF11, BIBREF12.We have achieved state-of-the-art results for the sentiment classification task for both Turkish and English.  As mentioned, our approaches, in general, perform best in predicting the labels of reviews when three supervised scores are additionality utilised.  We also employed the convolutional neural network model (CNN). the SVMifier, a, performed better.  We did not include the performances of CNN for embedding types here due to the page limit of the paper.  As a qualitative assessment of the word representations, given some query words we visualised the most similar words to those words using the cosine similarity metric.By assessing the similarities between a word and all the other corpus words, we can find the most akin words according to different approaches.  Table TABREF18 shows the most similar words to given query words.  Those words which are indicative of sentiment are, in general, found to be most similar to those words of the same polarity.  For example, the most akin word to muhteşem (gorgeous) is 10/10, both of which have positive polarity.As in Table TABREF, our corpus approach is more at capturingspecific features to word which captures semantic and syntactic characteristics, but not the sentimental ones.  Conclusion We have demonstrated that using word vectors that capture only semantic and syntactic characteristics may be improved by taking into account their sentimental aspects as well.Our approaches are--. They to other domains and languages than Turkish English minor.  Our is the few ones that perform sentiment analysis in Turkish and leverages sentimental characteristics of words in generating word vectors and outperforms all the others.  Any of the approaches we propose can be used independently of the others.Our approaches without using sentiment labels be to other as topic classification and concept mining.  The experiments show that even unsupervised approaches, as in the corpus-based approach, can outperform supervised approaches in classification tasks.  Combining some approaches, which can compensate for what others lack, can help us build better vectors.Our word vectors are created by conventional machine learning algorithms; however, they, as in the corpus-based model, produce state-of-the-art results.  Although we preferred to use a classical machine learning algorithm, which is SVM, over a neural network classifier to predict the labels of reviews, we achieved accuracies of over 90 per cent for the Turkish movie corpus and about 88 per cent for the English Twitter dataset.  We performed only binary sentiment classification in this study as most of the studies in the literature do.We will extend our system in future by using neutral reviews as well.  We also plan to employ Turkish WordNet to enhance the generalisability of our embeddings as another future work.  AcknowledgmentsThis byi University Research Fund Grant Number 6980D, and by Turkish Ministry of Development under the TAM Project number DPT2007K12-0610.  Cem Rıfkı Aydın is supported by TÜBİTAK BIDEB 2211E.... [The rest of the article is omitted]

Question:
How are the supervised scores of the words calculated?

Answer:
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>

