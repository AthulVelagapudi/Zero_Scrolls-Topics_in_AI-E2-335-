<|begin_of_text|><|start_header_id|>system<|end_header_id|>

You are a helpful assistant. Always follow the task instruction carefully. The first paragraph before the first double line break contains the task instruction. Generate text as a natural continuation of the user message. Do not include any meta-commentary or explanations.<|eot_id|>
<|start_header_id|>user<|end_header_id|>

You are given a scientific article and a question. Answer the question as concisely as you can, using a single phrase or sentence if possible. If the question cannot be answered based on the information in the article, write "unanswerable". If the question is a yes/no question, answer "yes", "no", or "unanswerable".

Article:
Introduction  Sarcasm is an intensive, indirect and complex construct that is often intended to express contempt or ridicule .  Sarcasm, in speech, is multi-modal, involving tone, body-language and gestures along with linguistic artifacts used in speech.Sasm in text more restrictive to such-istic This makes recognizing.  Sarcasm detection plays an indispensable role in applications like online review summarizers, dialog systems, recommendation systems and sentiment analyzers.  This makes automatic detection of sarcasm an important problem.However, it has been quite difficult to solve such a problem with traditional NLP tools and techniques.  This is apparent from the results reported by the survey from DBLP:journals/corr/JoshiBC16.  The following discussion brings more insights into this.Consider a scenario where an online reviewer gives a negative opinion about a movie through sarcasm:  “This is the kind of movie you see because the theater has air conditioning”.  It is difficult for an automatic sentiment analyzer to assign a rating to the movie and, in the absence of any other information, such a system may not be able to comprehend that prioritizing the air-conditioning facilities of the theater over the movie experience indicates a negative sentiment towards the movie.  This gives an intuition to why, for sarcasm detection, it is necessary to go beyond textual analysis.We to by exploiting the psycholinguistic side of sarcasm detection, using cognitive features extracted with the help of eye-tracking.  A motivation to consider cognitive features comes from analyzing human eye-movement trajectories that supports the conjecture:  Reading sarcastic texts induces distinctive eye movement patterns, compared to literal texts.The cognitive features, from human patterns include primary types:  The cognitive features, along with textual features used in best available sarcasm detectors, are used to train binary classifiers against given sarcasm labels.  Our experiments show significant improvement in classification accuracy over the state of the art, by performing such augmentation.Related Work Sarcasm, in general, has been the focus of research for quite some time.  In one of the pioneering works jorgensen1984test explained how sarcasm arises when a figurative meaning is used opposite to the literal meaning of the utterance.In the word of clark1984pretense, sarcasm processing involves canceling the indirectly negated message and replacing it with the implicated one.  giora1995irony, on the other hand, define sarcasm as a mode of indirect negation that requires processing of both negated and implicated messages.  ivanko2003context define sarcasm as a six tuple entity consisting of a speaker, a listener, Context, Utterance, Literal Proposition and Intended Proposition and study the cognitive aspects of sarcasm processing.Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of :  (a) Unigrams and Pragmatic features  BIBREF0, BIBREF1, BIBREF2, BIBREF3  (b) Stylistic patternsBIBREF4 and patterns related to situational disparity  BIBREF5 and (c)  Hastag interpretations BIBREF6, BIBREF7.Most of the previously done work on sarcasm detection uses distant supervision based techniques (ex: leveraging hashtags) and stylistic/pragmatic features (emoticons, laughter expressions such as “lol” etc).  But, detecting sarcasm in linguistically well-formed structures, in absence of explicit cues or information (like emoticons), proves to be hard using such linguistic/stylistic features alone.  With the advent of sophisticated eye-trackers and electro/magneto-encephalographic (EEG/MEG) devices, it has been possible to delve deep into the cognitive underpinnings of sarcasm understanding.Filik2014, using a series of eye-tracking and EEG experiments try to show that for unfamiliar ironies, the literal interpretation would be computed first.  They also show that a mismatch with context would lead to a re-interpretation of the statement, as being ironic.  Camblin2007103 show that in multi-sentence passages, discourse congruence has robust effects on eye movements. This also implies that disrupted processing occurs for discourse incongruent words, even though they are perfectly congruous at the sentence level.  In our previous work BIBREF8 , we augment cognitive features, derived from eye-movement patterns of readers, with textual features to detect whether a human reader has realized the presence of sarcasm in text or not.The recent advancements in the literature discussed above, motivate us to explore gaze-based cognition for sarcasm detection.  As far as we know, our work is the first of its kind.Eye-tracking Database for Sarcasm  Analysis  Sarcasm often emanates from incongruity BIBREF9, which enforces the brain to reanalyze it BIBREF10.This the way the. , the of successful of text texts.  This hypothesis forms the crux of our method for sarcasm detection and we validate this using our previously released freely available sarcasm dataset BIBREF8 enriched with gaze information.Document Description  The database consists of 1,000 short texts, each having 10-40 words.  Out of these, 350 are sarcastic and are collected as follows:) 103 sentences are from two popular sarcastic,) 76 sarcastic short are the Movie Corpus BIB two) are downloaded using the hashtag #sarcasm from Twitter.  The 650 non-sarcastic texts are either downloaded from Twitter or extracted from the Amazon Movie Review corpus.The sentences contain words are highly topic or.The were themistically formed avoid interpreting media   in dataset carries negative about specific� “The movie is extremely well cast” has positive sentiment about the aspect “cast”.The annotators were seven graduate students with science and engineering background, and possess good English proficiency.  They were given a set of instructions beforehand and are advised to seek clarifications before they proceed.  The instructions mention the nature of the task, annotation input method, and necessity of head movement minimization during the experiment.Task Description  The task assigned to annotators was to read sentences one at a time and label them with with binary labels indicating the polarity (i.e., positive/negative). that, the toate is., to the is expected, processing becomes easier BREF ).The setup ensures its� in(1) Readers are not given any clue that they have to treat sarcasm with special attention. is the toarity ( of).  ()ic sentences are mixed with non sarcastic text, which does not give prior knowledge about whether the forthcoming text will be sarcastic or not.  The eye-tracking experiment is conducted by following the standard norms in eye-movement research BIBREF13.At a time, one sentence is displayed to the reader along with the “aspect” with respect to which the annotation has to be provided.  While reading, an SR-Research Eyelink-1000 eye-tracker (monocular remote mode, sampling rate 500Hz) records several eye-movement parameters like fixations (a long stay of gaze) and saccade (quick jumping of gaze between two positions of rest) and pupil size.  The accuracy of polarity annotation varies between 72%-91% for sarcastic texts and 75%-91% for non-sarcastic text, showing the inherent difficulty of sentiment annotation, when sarcasm is present in the text under consideration.Annotation errors may be attributed to:  (a) lack of patience/attention while reading, (b) issues related to text comprehension, and  (c) confusion/indecisiveness caused due to lack of context.For our analysis, we do not discard the incorrect annotations present in the database.  Since our system eventually aims to involve online readers for sarcasm detection, it will be hard to segregate readers who misinterpret the text.  We make a rational assumption that, for a particular text, most of the readers, from a fairly large population, will be able to identify sarcasm.  Under this assumption, the eye-movement parameters, averaged across all readers in our setting, may not be significantly distorted by a few readers who would have failed to identify sarcasm.This assumption is applicable for both regular and multi-instance based classifiers explained in section SECREF6.  Analysis of Eye-movement DataWe observe distinct behavior during sarcasm reading, by analyzing the “fixation duration on the text” (also referred to as “dwell time” in the literature) and “scanpaths” of the readers.  Variation in the Average Fixation  Duration per WordSince sarcasm in text can be expected to induce cognitive load, it is reasonable to believe that it would require more processing time BIBREF14 .  Hence, fixation duration normalized over total word count should usually be higher for a sarcastic text than for a non-sarcastic one.  We observe this for all participants in our dataset, with the average fixation duration per word for sarcastic texts being at least 1.5 times more than that of non-sarcastic texts.To test the statistical significance, we conduct a two-tailed t-test (assuming unequal variance) to compare the average fixation duration per word for sarcastic and non-sarcastic texts.  The hypothesized mean difference is set to 0 and the error tolerance limit ( INLINEFORM0 ) is set to 0.05.  The t-test analysis, presented in Table TABREF11 , shows that for all participants, a statistically significant difference exists between the average fixation duration per word for sarcasm (higher average fixation duration) and non-sarcasm (lower average fixation duration).  This affirms that the presence of sarcasm affects the duration of fixation on words.It is important to note that longer fixations may also be caused by other linguistic subtleties (such as difficult words, ambiguity and syntactically complex structures) causing delay in comprehension, or occulomotor control problems forcing readers to spend time adjusting eye-muscles.  So, an elevated average fixation duration per word may not sufficiently indicate the presence of sarcasm.  But we would also like to share that, for our dataset, when we considered readability (Flesch readability ease-score BIBREF15 ), number of words in a sentence and average character per word along with the sarcasm label as the predictors of average fixation duration following a linear mixed effect model BIBREF16 , sarcasm label turned out to be the most significant predictor with a maximum slope.This indicates that average fixation duration per word has a strong connection with the text being sarcastic, at least in our dataset.  We now analyze scanpaths to gain more insights into the sarcasm comprehension process.Analysis of Scanpaths  Scanpaths are line-graphs that contain fixations as nodes and saccades as edges; the radii of the nodes represent the fixation duration.  A scanpath corresponds to a participant's eye-movement pattern while reading a particular sentence.Figure FIGREF14 presents scan of the sentencesarcastic sentence S2.  The x-axis of the graph represents the sequence of words a reader reads, and the y-axis represents a temporal sequence in milliseconds.  Consider a sarcastic text containing incongruous phrases A and B.Our qualitative scanpath-analysis reveals that scanpaths with respect to sarcasm processing have two typical characteristics.  Often, a long regression - a saccade that goes to a previously visited segment - is observed when a reader starts reading B after skimming through A.  In a few cases, the fixation duration on A and B are significantly higher than the average fixation duration per word.  In sentence S1, we see long and multiple regressions from the two incongruous phrases “misconception” and “cherish”, and a few instances where phrases “always cherish” and “original misconception” are fixated longer than usual.Such-ment not seen for S.  Thoughasm induces distinctives ones Figure FIGREF the observed, to also from literal, ands would help discriminative machine learning models learn sarcasm better.Features for Sarcasm Detection  We describe the features used for sarcasm detection in Table.The features enlisted under lexical,implicit incongruity and explicit incongruity are borrowed from various literature (predominantly from joshi2015harnessing).  These features are essential to separate sarcasm from other forms semantic incongruity in text (for example ambiguity arising from semantic ambiguity or from metaphors).  Two additional textual features viz. readability and word count of the text are also taken under consideration.  These features are used to reduce the effect of text hardness and text length on the eye-movement patterns.Simple Gaze Based Features  Readers' eye-movement behavior, characterized by fixations, forward saccades, skips and regressions, can be directly quantified by simple statistical aggregation (i.e., either computing features for individual participants and then averaging or performing a multi-instance based learning as explained in section SECREF6 ).Since these eye-movement attributes relate to the cognitive process in reading BIBREF17 , we consider these as features in our model.  Some of these features have been reported by sarcasmunderstandability for modeling sarcasm understandability of readers.  However, as far as we know, these features are being introduced in NLP tasks like textual sarcasm detection for the first time.  The values of these features are believed to increase with the increase in the degree of surprisal caused by incongruity in text (except skip count, which will decrease).Complex Gaze Based Features  For these features, we rely on a graph structure, namely “saliency graphs", derived from eye-gaze information and word sequences in the text.For each reader and each sentence, we construct a “saliency graph”, representing the reader's attention characteristics.  A saliency graph for a sentence INLINEFORM0 for a reader INLINEFORM1 , represented as INLINEFORM2 , is a graph with vertices ( INLINEFORM3 ) and edges ( INLINEFORM4 ) where each vertex INLINEFORM5 corresponds to a word in INLINEFORM6 (may not be unique) and there exists an edge INLINEFORM7 between vertices INLINEFORM8 and INLINEFORM9 if R performs at least one saccade between the words corresponding to INLINEFORM10 and INLINEFORM11 .Figure FIGREF15 shows an example of a saliency graph. A saliency graph may be weighted, but not necessarily connected, for a given text (as there may be words in the given text with no fixation on them).  The “complex” gaze features derived from saliency graphs are also motivated by the theory of incongruity.  For instance, Edge Density of a saliency graph increases with the number of distinct saccades, which could arise from the complexity caused by presence of sarcasm.Similarly, the highest weighted degree of a graph is expected to be higher, if the node corresponds to a phrase, incongruous to some other phrase in the text.  The Sarcasm ClassifierWe interpretasm.The data constitutes 9 examples using our-ment database  To our we of dataset a system best systems by riloff and j2015ing dataset.Using Weka BIBREF18 and LibSVM BIBREF19 APIs, we implement the following classifiers:  ResultsTable TABREF17 shows the classification results considering various feature combinations for different classifiers and other systems.  These are:  Unigram (with principal components of unigram feature vectors),Sarcasm (the feature-set reported by joshi2015harnessing subsuming unigram features and features from other reported systems)  Gaze (the simple and complex cognitive features we introduce, along with readability and word count features), andGaze+Sasm (the of). all regular the are across and with andasm the MIL classifier, the gaze features derived from each participant are augmented with linguistic features and thus, a multi instance “bag” of features is formed for each sentence in the training data.This multi-instance dataset is given to an MILR classifier, which follows the standard multi instance assumption to derive class-labels for each bag.  For all the classifiers, our feature combination outperforms the baselines (considering only unigram features) as well as BIBREF3 , with the MILR classifier getting an F-score improvement of 3.7% and Kappa difference of 0.08.  We also achieve an improvement of 2% over the baseline, using SVM classifier, when we employ our feature set.We also observe that the gaze features alone, also capture the differences between sarcasm and non-sarcasm classes with a high-precision but a low recall.  To see if the improvement obtained is statistically significant over the state-of-the art system with textual sarcasm features alone, we perform McNemar test.  The output of the SVM classifier using only linguistic features used for sarcasm detection by joshi2015harnessing and the output of the MILR classifier with the complete set of features are compared, setting threshold INLINEFORM0 .There was a significant difference in the classifier's accuracy with p(two-tailed) = 0.02 with an odds-ratio of 1.43, showing that the classification accuracy improvement is unlikely to be observed by chance in 95% confidence interval.  Considering Reading Time as a Cognitive Feature along with Sarcasm FeaturesOne may argue that, considering simple measures of reading effort like “reading time” as cognitive feature instead of the expensive eye-tracking features for sarcasm detection may be a cost-effective solution.  To examine this, we repeated our experiments with “reading time” considered as the only cognitive feature, augmented with the textual features.  The F-scores of all the classifiers turn out to be close to that of the classifiers considering sarcasm feature alone and the difference in the improvement is not statistically significant ( INLINEFORM0 ).  One the other hand, F-scores with gaze features are superior to the F-scores when reading time is considered as a cognitive feature.How Effective are the Cognitive Features  We examine the effectiveness of cognitive features on the classification accuracy by varying the input training data size.To we aified ( 80%. with 100%, data with our feature from joshi2015The our system is demonstrated by improvements in F-score and Kappa statistics, shown in Figure FIGREF22.We further analyze the importance of features by ranking the features based on (a) Chi squared test, and (b) Information Gain test, using Weka's attribute selection module.  Figure FIGREF23 shows the top 20 ranked features produced by both the tests.  For both the cases, we observe 16 out of top 20 features to be gaze features.  Further, in each of the cases, Average Fixation Duration per Word and Largest Regression Position are seen to be the two most significant features.Example Cases Table  TABREF21 shows a few example cases from the experiment with stratified 80%-20% train-test split.Example sentence 1 is sarcastic, and requires extra-linguistic knowledge (about poor living conditions at Manchester).  Hence, the sarcasm detector relying only on textual features is unable to detect the underlying incongruity.  However, our system predicts the label successfully, possibly helped by the gaze features.Similarly, for sentence 2, the false sense of presence of incongruity (due to phrases like “Helped me” and “Can't stop”) affects the system with only linguistic features.  Our system, though, performs well in this case also. 3 a false where was for even to the. why our gaze featuresand subsequently the complete set of features) account for erroneous prediction.  In sentence 4, gaze features alone false-indicate presence of incongruity, whereas the system predicts correctly when gaze and linguistic features are taken together.From these examples, it can be inferred that, only gaze features would not have sufficed to rule out the possibility of detecting other forms of incongruity that do not result in sarcasm.  Error AnalysisErrors committed by our system arise from multiple factors, starting from limitations of the eye-tracker hardware to errors committed by linguistic tools and resources.  Also, aggregating various eye-tracking parameters to extract the cognitive features may have caused information loss in the regular classification setting.  ConclusionIn the current work, we created a novel framework to detect sarcasm, that derives insights from human cognition, that manifests over eye movement patterns.  We hypothesized that distinctive eye-movement patterns, associated with reading sarcastic text, enables improved detection of sarcasm.  We augmented traditional linguistic features with cognitive features obtained from readers' eye-movement data in the form of simple gaze-based features and complex features derived from a graph structure.  This extended feature-set improved the success rate of the sarcasm detector by 3.7%, over the best available system.Using cognitive features in anLP system like is first.Our approachLP sub-areas like sentiment and emotion analysis, text summarization and question answering, where considering textual clues alone does not prove to be sufficient.  We propose to augment this work in future by exploring deeper graph and gaze features.We also propose to develop models for the purpose of learning complex gaze feature representation, that accounts for the power of individual eye movement patterns along with the aggregated patterns of eye movements.  AcknowledgmentsWe thank the members of CFILT Lab, especially Jaya Jha and Meghna Singh, and the students of IIT Bombay for their help and support.... [The rest of the article is omitted]

Question:
What traditional linguistics features did they use?

Answer:
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>

